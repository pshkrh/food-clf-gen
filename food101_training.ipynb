{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4z_9-L2TeqWg"
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q scikit-learn pandas tqdm kaggle matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following NEW packages will be installed:\n",
      "  unzip zip\n",
      "0 upgraded, 2 newly installed, 0 to remove and 16 not upgraded.\n",
      "Need to get 335 kB of archives.\n",
      "After this operation, 1231 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 unzip amd64 6.0-25ubuntu1.1 [168 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 zip amd64 3.0-11build1 [167 kB]\n",
      "Fetched 335 kB in 0s (1155 kB/s)\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package unzip.\n",
      "(Reading database ... 17208 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-25ubuntu1.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Unpacking unzip (6.0-25ubuntu1.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [############..............................................] \u001b8Selecting previously unselected package zip.\n",
      "Preparing to unpack .../zip_3.0-11build1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Unpacking zip (3.0-11build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 44%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Setting up unzip (6.0-25ubuntu1.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up zip (3.0-11build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [#############################################.............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 89%]\u001b[49m\u001b[39m [###################################################.......] \u001b8Processing triggers for mime-support (3.64ubuntu1) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "!sudo apt -q install zip unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Jakcr3LgiW3M"
   },
   "outputs": [],
   "source": [
    "!chmod 600 kaggle.json  # Ensure the file is private\n",
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download the dataset\n",
    "# !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
    "\n",
    "# # Extract the dataset\n",
    "# !tar -xzvf food-101.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKatJ664iaKr",
    "outputId": "a63e76b1-cf0e-4901-ec21-85120a8f4034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading food-101.zip to /\n",
      "100%|██████████████████████████████████████| 9.38G/9.38G [05:52<00:00, 34.2MB/s]\n",
      "100%|██████████████████████████████████████| 9.38G/9.38G [05:52<00:00, 28.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d dansbecker/food-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKatJ664iaKr",
    "outputId": "a63e76b1-cf0e-4901-ec21-85120a8f4034"
   },
   "outputs": [],
   "source": [
    "!unzip -q food-101.zip -d food-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "l2mDZ8uRS3mX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FBFH6rWvmnDA"
   },
   "outputs": [],
   "source": [
    "model_save_dir = 'Trained_Models'\n",
    "os.makedirs(model_save_dir, exist_ok=True)  # Create the directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-D0DgwBkesBz"
   },
   "source": [
    "Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "# Define the paths and split ratios\n",
    "source_dir = 'food-101/food-101/food-101/images'  # Replace with source directory path\n",
    "destination_dir = 'data'  # Replace with destination directory path\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# Create train, val, and test directories in the destination folder\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_dir = os.path.join(destination_dir, split)\n",
    "    os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "# Move files into splits\n",
    "for class_dir in os.listdir(source_dir):\n",
    "    class_path = os.path.join(source_dir, class_dir)\n",
    "    if os.path.isdir(class_path):\n",
    "        images = os.listdir(class_path)\n",
    "        np.random.shuffle(images)\n",
    "        \n",
    "        train_split = int(train_ratio * len(images))\n",
    "        val_split = int(val_ratio * len(images))\n",
    "\n",
    "        # Creating subdirectories for each class in train, val, and test in the destination folder\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            split_class_dir = os.path.join(destination_dir, split, class_dir)\n",
    "            os.makedirs(split_class_dir, exist_ok=True)\n",
    "        \n",
    "        # Copy images to respective directories in the destination folder\n",
    "        for i, image in enumerate(images):\n",
    "            if i < train_split:\n",
    "                split = 'train'\n",
    "            elif i < train_split + val_split:\n",
    "                split = 'val'\n",
    "            else:\n",
    "                split = 'test'\n",
    "\n",
    "            src_path = os.path.join(class_path, image)\n",
    "            dest_path = os.path.join(destination_dir, split, class_dir, image)\n",
    "            shutil.copy(src_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "El1j9zCMTBWz"
   },
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define your transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = datasets.ImageFolder(root=os.path.join(destination_dir, 'train'), transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=os.path.join(destination_dir, 'val'), transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=os.path.join(destination_dir, 'test'), transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0OlNTlcevFG"
   },
   "source": [
    "Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xp3V97Zwev1z",
    "outputId": "321eb893-d8ce-47d3-ce86-a9070c8cb4c3"
   },
   "outputs": [],
   "source": [
    "def get_model(pretrained=True):\n",
    "    return {\n",
    "        'EfficientNetV2': models.efficientnet_v2_s(pretrained=pretrained),\n",
    "        'ResNet50': models.resnet50(pretrained=pretrained),\n",
    "        'VGG16': models.vgg16(pretrained=pretrained),\n",
    "        'MobileNetV3': models.mobilenet_v3_large(pretrained=pretrained),\n",
    "        'DenseNet121': models.densenet121(pretrained=pretrained)\n",
    "    }\n",
    "\n",
    "def modify_model_classes(model_dict, num_classes):\n",
    "    for name, model in model_dict.items():\n",
    "        if name == 'EfficientNetV2':\n",
    "            num_ftrs = model.classifier[1].in_features\n",
    "            model.classifier[1] = torch.nn.Linear(num_ftrs, num_classes)\n",
    "        elif name == 'ResNet50':\n",
    "            num_ftrs = model.fc.in_features\n",
    "            model.fc = torch.nn.Linear(num_ftrs, num_classes)\n",
    "        elif name == 'VGG16':\n",
    "            num_ftrs = model.classifier[6].in_features\n",
    "            model.classifier[6] = torch.nn.Linear(num_ftrs, num_classes)\n",
    "        elif name == 'MobileNetV3':\n",
    "            num_ftrs = model.classifier[3].in_features\n",
    "            model.classifier[3] = torch.nn.Linear(num_ftrs, num_classes)\n",
    "        elif name == 'DenseNet121':\n",
    "            num_ftrs = model.classifier.in_features\n",
    "            model.classifier = torch.nn.Linear(num_ftrs, num_classes)\n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xp3V97Zwev1z",
    "outputId": "321eb893-d8ce-47d3-ce86-a9070c8cb4c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n",
      "100%|██████████| 82.7M/82.7M [00:00<00:00, 104MB/s] \n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 107MB/s] \n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:05<00:00, 106MB/s]  \n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-8738ca79.pth\n",
      "100%|██████████| 21.1M/21.1M [00:00<00:00, 69.1MB/s]\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
      "100%|██████████| 30.8M/30.8M [00:00<00:00, 80.0MB/s]\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "pretrained_models = modify_model_classes(get_model(pretrained=True), num_classes=101)\n",
    "non_pretrained_models = modify_model_classes(get_model(pretrained=False), num_classes=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07hp94MKe05g"
   },
   "source": [
    "Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xqRhNGNue17f"
   },
   "outputs": [],
   "source": [
    "def train_and_validate_model(model, train_loader, val_loader, epochs=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if torch.cuda.device_count() > 1:\n",
    "      print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "      model = nn.DataParallel(model)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    best_val_accuracy = 0\n",
    "\n",
    "    # Lists to store per epoch metrics\n",
    "    epoch_train_losses = []\n",
    "    epoch_train_accuracies = []\n",
    "    epoch_val_losses = []\n",
    "    epoch_val_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_accuracy = train_correct / train_total\n",
    "        epoch_train_losses.append(train_loss / len(train_loader))\n",
    "        epoch_train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "\n",
    "        epoch_val_losses.append(val_loss / len(val_loader))\n",
    "        epoch_val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader)}, Val Loss: {val_loss/len(val_loader)}, Val Accuracy: {val_accuracy}')\n",
    "\n",
    "        # Update best model if validation accuracy improves\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model_wts = model.state_dict()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, epoch_train_losses, epoch_train_accuracies, epoch_val_losses, epoch_val_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sMdh0WEDgbW-"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    return precision, recall, f1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lz5qTQqme483",
    "outputId": "ebbe4913-a553-4ae9-89a8-afa7e874965a"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(model_dict, pretrained_status, epochs=10):\n",
    "    results_df = pd.DataFrame(columns=['Model', 'Pretrained', 'Precision', 'Recall', 'F1 Score', 'Accuracy'])\n",
    "\n",
    "    metrics_dict = {}\n",
    "    \n",
    "    for name, model in model_dict.items():\n",
    "        print(f\"Training and validating {name} (Pretrained: {pretrained_status})\")\n",
    "        trained_model, train_losses, train_accuracies, val_losses, val_accuracies = train_and_validate_model(model, train_loader, val_loader, epochs=epochs)\n",
    "\n",
    "        # Store metrics for plotting\n",
    "        metrics_dict[name] = {\n",
    "            'train_losses': train_losses,\n",
    "            'train_accuracies': train_accuracies,\n",
    "            'val_losses': val_losses,\n",
    "            'val_accuracies': val_accuracies\n",
    "        }\n",
    "\n",
    "        # Saving the trained model\n",
    "        model_path = os.path.join(model_save_dir, f'{name}_{\"pretrained\" if pretrained_status else \"non_pretrained\"}.pt')\n",
    "        torch.save(trained_model.state_dict(), model_path)\n",
    "        print(f\"Saved trained model at {model_path}\")\n",
    "        \n",
    "        print(f\"Evaluating {name} (Pretrained: {pretrained_status})\")\n",
    "        precision, recall, f1, accuracy = evaluate_model(trained_model, test_loader)\n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}, Accuracy: {accuracy}\")\n",
    "        results_df.loc[len(results_df.index)] = [name, pretrained_status, precision, recall, f1, accuracy]\n",
    "        \n",
    "    return results_df, metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lz5qTQqme483",
    "outputId": "ebbe4913-a553-4ae9-89a8-afa7e874965a"
   },
   "outputs": [],
   "source": [
    "# Train and evaluate pretrained models\n",
    "pretrained_results_df, pretrained_metrics = train_and_evaluate_models(pretrained_models, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Pretrained</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EfficientNet</td>\n",
       "      <td>True</td>\n",
       "      <td>0.829306</td>\n",
       "      <td>0.827624</td>\n",
       "      <td>0.827476</td>\n",
       "      <td>0.827624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ResNet</td>\n",
       "      <td>True</td>\n",
       "      <td>0.751379</td>\n",
       "      <td>0.748020</td>\n",
       "      <td>0.748540</td>\n",
       "      <td>0.748020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VGG</td>\n",
       "      <td>True</td>\n",
       "      <td>0.317313</td>\n",
       "      <td>0.330099</td>\n",
       "      <td>0.319110</td>\n",
       "      <td>0.330099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MobileNet</td>\n",
       "      <td>True</td>\n",
       "      <td>0.779271</td>\n",
       "      <td>0.777822</td>\n",
       "      <td>0.777975</td>\n",
       "      <td>0.777822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DenseNet</td>\n",
       "      <td>True</td>\n",
       "      <td>0.799960</td>\n",
       "      <td>0.798317</td>\n",
       "      <td>0.798242</td>\n",
       "      <td>0.798317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Pretrained  Precision    Recall  F1 Score  Accuracy\n",
       "0  EfficientNet        True   0.829306  0.827624  0.827476  0.827624\n",
       "1        ResNet        True   0.751379  0.748020  0.748540  0.748020\n",
       "2           VGG        True   0.317313  0.330099  0.319110  0.330099\n",
       "3     MobileNet        True   0.779271  0.777822  0.777975  0.777822\n",
       "4      DenseNet        True   0.799960  0.798317  0.798242  0.798317"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ruqjW20amREK"
   },
   "outputs": [],
   "source": [
    "current_timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "filename = f'results_pretrained_{current_timestamp}.csv'\n",
    "pretrained_results_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lz5qTQqme483",
    "outputId": "ebbe4913-a553-4ae9-89a8-afa7e874965a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validating EfficientNet (Pretrained: False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:18<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 4.375394216943734, Val Loss: 4.228005222127408, Val Accuracy: 0.05638613861386139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:17<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 3.8542740870038523, Val Loss: 3.7903696464586862, Val Accuracy: 0.11861386138613861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:17<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 3.378885016114273, Val Loss: 3.229848986939539, Val Accuracy: 0.22287128712871287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:17<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 2.9009540657704487, Val Loss: 2.7726997363416452, Val Accuracy: 0.31445544554455446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:17<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 2.4853109581806168, Val Loss: 2.573833977119832, Val Accuracy: 0.36178217821782177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:17<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 2.113519678477346, Val Loss: 2.2089012242570707, Val Accuracy: 0.4443069306930693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:17<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 1.8418141792827565, Val Loss: 1.990254767333405, Val Accuracy: 0.4925247524752475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:17<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 1.3377747290401252, Val Loss: 1.7142092087600804, Val Accuracy: 0.5613366336633664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:17<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 1.185565534481503, Val Loss: 1.696402202678632, Val Accuracy: 0.5695049504950495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:17<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 1.0945558421017891, Val Loss: 1.7048886999299255, Val Accuracy: 0.5677722772277227\n",
      "Saved trained model at /Trained_Models/EfficientNet_non_pretrained.pt\n",
      "Evaluating EfficientNet (Pretrained: False)\n",
      "Precision: 0.5748205129472024, Recall: 0.5742574257425742, F1 Score: 0.5716025749300604, Accuracy: 0.5742574257425742\n",
      "Training and validating ResNet (Pretrained: False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 4.253155624823449, Val Loss: 4.122869560990153, Val Accuracy: 0.07811881188118812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 3.6749575052020353, Val Loss: 3.8199616383902635, Val Accuracy: 0.13173267326732674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 3.253664806001023, Val Loss: 3.4093002941035015, Val Accuracy: 0.19806930693069308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 2.843223584688097, Val Loss: 3.0478779877288433, Val Accuracy: 0.26321782178217823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 2.467091228127049, Val Loss: 2.927686593200587, Val Accuracy: 0.2906930693069307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 2.160091203903033, Val Loss: 2.8466111987451965, Val Accuracy: 0.31925742574257426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 1.893175961308531, Val Loss: 2.7008066863953313, Val Accuracy: 0.37143564356435643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 1.3013152196088853, Val Loss: 1.8015197538122345, Val Accuracy: 0.5500495049504951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 1.1220241612906061, Val Loss: 1.793411660043499, Val Accuracy: 0.5543564356435644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.99982805802934, Val Loss: 1.8884781968744495, Val Accuracy: 0.550940594059406\n",
      "Saved trained model at /Trained_Models/ResNet_non_pretrained.pt\n",
      "Evaluating ResNet (Pretrained: False)\n",
      "Precision: 0.5637328055317504, Recall: 0.5523762376237624, F1 Score: 0.551025507950444, Accuracy: 0.5523762376237624\n",
      "Training and validating VGG (Pretrained: False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:45<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 8.658925445501556, Val Loss: 4.6151470836204815, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:45<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 4.615432458664106, Val Loss: 4.615135663672339, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:45<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 4.615392500743108, Val Loss: 4.6151297665849516, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:45<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 4.615399587885998, Val Loss: 4.615129651902597, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:45<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 4.615371218657235, Val Loss: 4.615130629720567, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:44<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 4.615424505640023, Val Loss: 4.6151293018196204, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:44<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 4.615389737841885, Val Loss: 4.615129325963274, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:44<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 4.615096625868595, Val Loss: 4.615129132814046, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:44<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 4.615106926928358, Val Loss: 4.6151288370542884, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:45<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 4.615122049724152, Val Loss: 4.615127992026413, Val Accuracy: 0.009900990099009901\n",
      "Saved trained model at /Trained_Models/VGG_non_pretrained.pt\n",
      "Evaluating VGG (Pretrained: False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 9.802960494069208e-05, Recall: 0.009900990099009901, F1 Score: 0.00019413706076490002, Accuracy: 0.009900990099009901\n",
      "Training and validating MobileNet (Pretrained: False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:45<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 4.098104840151239, Val Loss: 4.912214083007619, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:45<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 3.4789439332183947, Val Loss: 4.373997048486637, Val Accuracy: 0.06668316831683169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:45<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 3.033961319320899, Val Loss: 3.360474853575984, Val Accuracy: 0.2253960396039604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:45<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 2.6509630783370257, Val Loss: 4.233963552909561, Val Accuracy: 0.174009900990099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:45<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 2.297640343865763, Val Loss: 2.924119659616977, Val Accuracy: 0.3149009900990099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:44<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 2.0091255696671966, Val Loss: 2.699534363384488, Val Accuracy: 0.36044554455445543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:44<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 1.757824422650389, Val Loss: 2.3875065166738967, Val Accuracy: 0.4268316831683168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:45<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 1.2378782283528187, Val Loss: 1.9444368783431718, Val Accuracy: 0.5143069306930693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:45<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 1.0748085142903379, Val Loss: 1.9683504225332527, Val Accuracy: 0.5220792079207921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:44<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.9730644462771364, Val Loss: 2.046131933791728, Val Accuracy: 0.520940594059406\n",
      "Saved trained model at /Trained_Models/MobileNet_non_pretrained.pt\n",
      "Evaluating MobileNet (Pretrained: False)\n",
      "Precision: 0.5214854151710981, Recall: 0.5201980198019802, F1 Score: 0.5171336156977725, Accuracy: 0.5201980198019802\n",
      "Training and validating DenseNet (Pretrained: False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:15<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 3.8438786616824596, Val Loss: 3.7369838605953167, Val Accuracy: 0.1404950495049505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 3.1280533329244125, Val Loss: 3.2476641769650616, Val Accuracy: 0.22777227722772278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 2.598802169737833, Val Loss: 3.1820791914493225, Val Accuracy: 0.26034653465346536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 2.2120876828685994, Val Loss: 2.447665984117532, Val Accuracy: 0.39910891089108913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 1.9077451784257855, Val Loss: 2.4208519383321834, Val Accuracy: 0.41767326732673266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 1.6743637710702117, Val Loss: 2.2103187502185, Val Accuracy: 0.457970297029703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 1.4758727830239582, Val Loss: 2.005479040025156, Val Accuracy: 0.5014356435643564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:14<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 1.0241381676618804, Val Loss: 1.4399222588237328, Val Accuracy: 0.6272772277227723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.8998948043003839, Val Loss: 1.4025480694408659, Val Accuracy: 0.6384653465346535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.8340397582587783, Val Loss: 1.3974817772454853, Val Accuracy: 0.6416831683168317\n",
      "Saved trained model at /Trained_Models/DenseNet_non_pretrained.pt\n",
      "Evaluating DenseNet (Pretrained: False)\n",
      "Precision: 0.6457570051936392, Recall: 0.6420792079207921, F1 Score: 0.6412335839847823, Accuracy: 0.6420792079207921\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate non-pretrained models\n",
    "non_pretrained_results_df, non_pretrained_metrics = train_and_evaluate_models(non_pretrained_models, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Pretrained</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EfficientNet</td>\n",
       "      <td>False</td>\n",
       "      <td>0.574821</td>\n",
       "      <td>0.574257</td>\n",
       "      <td>0.571603</td>\n",
       "      <td>0.574257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ResNet</td>\n",
       "      <td>False</td>\n",
       "      <td>0.563733</td>\n",
       "      <td>0.552376</td>\n",
       "      <td>0.551026</td>\n",
       "      <td>0.552376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VGG</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.009901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MobileNet</td>\n",
       "      <td>False</td>\n",
       "      <td>0.521485</td>\n",
       "      <td>0.520198</td>\n",
       "      <td>0.517134</td>\n",
       "      <td>0.520198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DenseNet</td>\n",
       "      <td>False</td>\n",
       "      <td>0.645757</td>\n",
       "      <td>0.642079</td>\n",
       "      <td>0.641234</td>\n",
       "      <td>0.642079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Pretrained  Precision    Recall  F1 Score  Accuracy\n",
       "0  EfficientNet       False   0.574821  0.574257  0.571603  0.574257\n",
       "1        ResNet       False   0.563733  0.552376  0.551026  0.552376\n",
       "2           VGG       False   0.000098  0.009901  0.000194  0.009901\n",
       "3     MobileNet       False   0.521485  0.520198  0.517134  0.520198\n",
       "4      DenseNet       False   0.645757  0.642079  0.641234  0.642079"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_pretrained_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "filename = f'results_nonpretrained_{current_timestamp}.csv'\n",
    "non_pretrained_results_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'pt_metrics_{current_timestamp}.pickle', 'wb') as handle:\n",
    "    pickle.dump(pretrained_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'npt_metrics_{current_timestamp}.pickle', 'wb') as handle:\n",
    "    pickle.dump(non_pretrained_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "for model_name in pretrained_models.keys():\n",
    "    pt_epochs_range = range(1, 10 + 1)\n",
    "    npt_epochs_range = range(1, 20 + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot for pretrained model\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(pt_epochs_range, pretrained_metrics[model_name][\"train_losses\"], color='blue', label='Training Loss')\n",
    "    plt.plot(pt_epochs_range, pretrained_metrics[model_name][\"val_losses\"], color='red', label='Validation Loss')\n",
    "    plt.plot(pt_epochs_range, pretrained_metrics[model_name][\"train_accuracies\"], color='orange', label='Training Accuracy')\n",
    "    plt.plot(pt_epochs_range, pretrained_metrics[model_name][\"val_accuracies\"], color='green', label='Validation Accuracy')\n",
    "    plt.title(f'{model_name} Pretrained')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Metrics')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot for non-pretrained model\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(npt_epochs_range, non_pretrained_metrics[model_name][\"train_losses\"], color='blue', label='Training Loss')\n",
    "    plt.plot(npt_epochs_range, non_pretrained_metrics[model_name][\"val_losses\"], color='red', label='Validation Loss')\n",
    "    plt.plot(npt_epochs_range, non_pretrained_metrics[model_name][\"train_accuracies\"], color='orange', label='Training Accuracy')\n",
    "    plt.plot(npt_epochs_range, non_pretrained_metrics[model_name][\"val_accuracies\"], color='green', label='Validation Accuracy')\n",
    "    plt.title(f'{model_name} Non-Pretrained')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Metrics')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
