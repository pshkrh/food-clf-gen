{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4z_9-L2TeqWg"
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q scikit-learn pandas tqdm kaggle matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following NEW packages will be installed:\n",
      "  unzip zip\n",
      "0 upgraded, 2 newly installed, 0 to remove and 16 not upgraded.\n",
      "Need to get 335 kB of archives.\n",
      "After this operation, 1231 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 unzip amd64 6.0-25ubuntu1.1 [168 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 zip amd64 3.0-11build1 [167 kB]\n",
      "Fetched 335 kB in 0s (1155 kB/s)\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001B7\u001B[0;23r\u001B8\u001B[1ASelecting previously unselected package unzip.\n",
      "(Reading database ... 17208 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-25ubuntu1.1_amd64.deb ...\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [  0%]\u001B[49m\u001B[39m [..........................................................] \u001B8\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 11%]\u001B[49m\u001B[39m [######....................................................] \u001B8Unpacking unzip (6.0-25ubuntu1.1) ...\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 22%]\u001B[49m\u001B[39m [############..............................................] \u001B8Selecting previously unselected package zip.\n",
      "Preparing to unpack .../zip_3.0-11build1_amd64.deb ...\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 33%]\u001B[49m\u001B[39m [###################.......................................] \u001B8Unpacking zip (3.0-11build1) ...\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 44%]\u001B[49m\u001B[39m [#########################.................................] \u001B8Setting up unzip (6.0-25ubuntu1.1) ...\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 56%]\u001B[49m\u001B[39m [################################..........................] \u001B8\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 67%]\u001B[49m\u001B[39m [######################################....................] \u001B8Setting up zip (3.0-11build1) ...\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 78%]\u001B[49m\u001B[39m [#############################################.............] \u001B8\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 89%]\u001B[49m\u001B[39m [###################################################.......] \u001B8Processing triggers for mime-support (3.64ubuntu1) ...\n",
      "\n",
      "\u001B7\u001B[0;24r\u001B8\u001B[1A\u001B[J"
     ]
    }
   ],
   "source": [
    "!sudo apt -q install zip unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Jakcr3LgiW3M"
   },
   "outputs": [],
   "source": [
    "!chmod 600 kaggle.json  # Ensure the file is private\n",
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download the dataset\n",
    "# !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
    "\n",
    "# # Extract the dataset\n",
    "# !tar -xzvf food-101.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKatJ664iaKr",
    "outputId": "a63e76b1-cf0e-4901-ec21-85120a8f4034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading food-101.zip to /\n",
      "100%|██████████████████████████████████████| 9.38G/9.38G [05:52<00:00, 34.2MB/s]\n",
      "100%|██████████████████████████████████████| 9.38G/9.38G [05:52<00:00, 28.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d dansbecker/food-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKatJ664iaKr",
    "outputId": "a63e76b1-cf0e-4901-ec21-85120a8f4034"
   },
   "outputs": [],
   "source": [
    "!unzip -q food-101.zip -d food-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "l2mDZ8uRS3mX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FBFH6rWvmnDA"
   },
   "outputs": [],
   "source": [
    "model_save_dir = 'Trained_Models'\n",
    "os.makedirs(model_save_dir, exist_ok=True)  # Create the directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-D0DgwBkesBz"
   },
   "source": [
    "Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "# Define the paths and split ratios\n",
    "source_dir = 'food-101/food-101/food-101/images'  # Replace with source directory path\n",
    "destination_dir = 'data'  # Replace with destination directory path\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# Create train, val, and test directories in the destination folder\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_dir = os.path.join(destination_dir, split)\n",
    "    os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "# Move files into splits\n",
    "for class_dir in os.listdir(source_dir):\n",
    "    class_path = os.path.join(source_dir, class_dir)\n",
    "    if os.path.isdir(class_path):\n",
    "        images = os.listdir(class_path)\n",
    "        np.random.shuffle(images)\n",
    "        \n",
    "        train_split = int(train_ratio * len(images))\n",
    "        val_split = int(val_ratio * len(images))\n",
    "\n",
    "        # Creating subdirectories for each class in train, val, and test in the destination folder\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            split_class_dir = os.path.join(destination_dir, split, class_dir)\n",
    "            os.makedirs(split_class_dir, exist_ok=True)\n",
    "        \n",
    "        # Copy images to respective directories in the destination folder\n",
    "        for i, image in enumerate(images):\n",
    "            if i < train_split:\n",
    "                split = 'train'\n",
    "            elif i < train_split + val_split:\n",
    "                split = 'val'\n",
    "            else:\n",
    "                split = 'test'\n",
    "\n",
    "            src_path = os.path.join(class_path, image)\n",
    "            dest_path = os.path.join(destination_dir, split, class_dir, image)\n",
    "            shutil.copy(src_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "El1j9zCMTBWz"
   },
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define your transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = datasets.ImageFolder(root=os.path.join(destination_dir, 'train'), transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=os.path.join(destination_dir, 'val'), transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=os.path.join(destination_dir, 'test'), transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0OlNTlcevFG"
   },
   "source": [
    "Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xp3V97Zwev1z",
    "outputId": "321eb893-d8ce-47d3-ce86-a9070c8cb4c3"
   },
   "outputs": [],
   "source": [
    "def get_model(pretrained=True):\n",
    "    return {\n",
    "        'EfficientNetV2': models.efficientnet_v2_s(pretrained=pretrained),\n",
    "        'ResNet50': models.resnet50(pretrained=pretrained),\n",
    "        'VGG16': models.vgg16(pretrained=pretrained),\n",
    "        'MobileNetV3': models.mobilenet_v3_large(pretrained=pretrained),\n",
    "        'DenseNet121': models.densenet121(pretrained=pretrained)\n",
    "    }\n",
    "\n",
    "def modify_model_classes(model_dict, num_classes):\n",
    "    for name, model in model_dict.items():\n",
    "        if name == 'EfficientNetV2':\n",
    "            num_ftrs = model.classifier[1].in_features\n",
    "            model.classifier[1] = torch.nn.Linear(num_ftrs, num_classes)\n",
    "        elif name == 'ResNet50':\n",
    "            num_ftrs = model.fc.in_features\n",
    "            model.fc = torch.nn.Linear(num_ftrs, num_classes)\n",
    "        elif name == 'VGG16':\n",
    "            num_ftrs = model.classifier[6].in_features\n",
    "            model.classifier[6] = torch.nn.Linear(num_ftrs, num_classes)\n",
    "        elif name == 'MobileNetV3':\n",
    "            num_ftrs = model.classifier[3].in_features\n",
    "            model.classifier[3] = torch.nn.Linear(num_ftrs, num_classes)\n",
    "        elif name == 'DenseNet121':\n",
    "            num_ftrs = model.classifier.in_features\n",
    "            model.classifier = torch.nn.Linear(num_ftrs, num_classes)\n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xp3V97Zwev1z",
    "outputId": "321eb893-d8ce-47d3-ce86-a9070c8cb4c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n",
      "100%|██████████| 82.7M/82.7M [00:00<00:00, 104MB/s] \n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 107MB/s] \n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:05<00:00, 106MB/s]  \n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-8738ca79.pth\n",
      "100%|██████████| 21.1M/21.1M [00:00<00:00, 69.1MB/s]\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
      "100%|██████████| 30.8M/30.8M [00:00<00:00, 80.0MB/s]\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "pretrained_models = modify_model_classes(get_model(pretrained=True), num_classes=101)\n",
    "non_pretrained_models = modify_model_classes(get_model(pretrained=False), num_classes=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07hp94MKe05g"
   },
   "source": [
    "Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xqRhNGNue17f"
   },
   "outputs": [],
   "source": [
    "def train_and_validate_model(model, train_loader, val_loader, epochs=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if torch.cuda.device_count() > 1:\n",
    "      print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "      model = nn.DataParallel(model)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    best_val_accuracy = 0\n",
    "\n",
    "    # Lists to store per epoch metrics\n",
    "    epoch_train_losses = []\n",
    "    epoch_train_accuracies = []\n",
    "    epoch_val_losses = []\n",
    "    epoch_val_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_accuracy = train_correct / train_total\n",
    "        epoch_train_losses.append(train_loss / len(train_loader))\n",
    "        epoch_train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "\n",
    "        epoch_val_losses.append(val_loss / len(val_loader))\n",
    "        epoch_val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader)}, Val Loss: {val_loss/len(val_loader)}, Val Accuracy: {val_accuracy}')\n",
    "\n",
    "        # Update best model if validation accuracy improves\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model_wts = model.state_dict()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, epoch_train_losses, epoch_train_accuracies, epoch_val_losses, epoch_val_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sMdh0WEDgbW-"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    return precision, recall, f1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lz5qTQqme483",
    "outputId": "ebbe4913-a553-4ae9-89a8-afa7e874965a"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(model_dict, pretrained_status, epochs=10):\n",
    "    results_df = pd.DataFrame(columns=['Model', 'Pretrained', 'Precision', 'Recall', 'F1 Score', 'Accuracy'])\n",
    "\n",
    "    metrics_dict = {}\n",
    "    \n",
    "    for name, model in model_dict.items():\n",
    "        print(f\"Training and validating {name} (Pretrained: {pretrained_status})\")\n",
    "        trained_model, train_losses, train_accuracies, val_losses, val_accuracies = train_and_validate_model(model, train_loader, val_loader, epochs=epochs)\n",
    "\n",
    "        # Store metrics for plotting\n",
    "        metrics_dict[name] = {\n",
    "            'train_losses': train_losses,\n",
    "            'train_accuracies': train_accuracies,\n",
    "            'val_losses': val_losses,\n",
    "            'val_accuracies': val_accuracies\n",
    "        }\n",
    "\n",
    "        # Saving the trained model\n",
    "        model_path = os.path.join(model_save_dir, f'{name}_{\"pretrained\" if pretrained_status else \"non_pretrained\"}.pt')\n",
    "        torch.save(trained_model.state_dict(), model_path)\n",
    "        print(f\"Saved trained model at {model_path}\")\n",
    "        \n",
    "        print(f\"Evaluating {name} (Pretrained: {pretrained_status})\")\n",
    "        precision, recall, f1, accuracy = evaluate_model(trained_model, test_loader)\n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}, Accuracy: {accuracy}\")\n",
    "        results_df.loc[len(results_df.index)] = [name, pretrained_status, precision, recall, f1, accuracy]\n",
    "        \n",
    "    return results_df, metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lz5qTQqme483",
    "outputId": "ebbe4913-a553-4ae9-89a8-afa7e874965a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validating EfficientNet (Pretrained: True)\n",
      "Using 2 GPUs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/139 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Train and evaluate pretrained models\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m pretrained_results_df, pretrained_metrics \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_evaluate_models\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpretrained_models\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[34], line 8\u001B[0m, in \u001B[0;36mtrain_and_evaluate_models\u001B[0;34m(model_dict, pretrained_status, epochs)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, model \u001B[38;5;129;01min\u001B[39;00m model_dict\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining and validating \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (Pretrained: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrained_status\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 8\u001B[0m     trained_model, train_losses, train_accuracies, val_losses, val_accuracies \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_validate_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;66;03m# Store metrics for plotting\u001B[39;00m\n\u001B[1;32m     11\u001B[0m     metrics_dict[name] \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_losses\u001B[39m\u001B[38;5;124m'\u001B[39m: train_losses,\n\u001B[1;32m     13\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_accuracies\u001B[39m\u001B[38;5;124m'\u001B[39m: train_accuracies,\n\u001B[1;32m     14\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_losses\u001B[39m\u001B[38;5;124m'\u001B[39m: val_losses,\n\u001B[1;32m     15\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_accuracies\u001B[39m\u001B[38;5;124m'\u001B[39m: val_accuracies\n\u001B[1;32m     16\u001B[0m     }\n",
      "Cell \u001B[0;32mIn[32], line 27\u001B[0m, in \u001B[0;36mtrain_and_validate_model\u001B[0;34m(model, train_loader, val_loader, epochs)\u001B[0m\n\u001B[1;32m     25\u001B[0m train_correct \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     26\u001B[0m train_total \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m---> 27\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m inputs, labels \u001B[38;5;129;01min\u001B[39;00m tqdm(train_loader):\n\u001B[1;32m     28\u001B[0m     inputs, labels \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     29\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1178\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1175\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1178\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1179\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1180\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1181\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1328\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[1;32m   1327\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m-> 1328\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1329\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1330\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[1;32m   1331\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1294\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1290\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[1;32m   1291\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[1;32m   1292\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1293\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 1294\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1295\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[1;32m   1296\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1132\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1119\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_get_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_utils\u001B[38;5;241m.\u001B[39mMP_STATUS_CHECK_INTERVAL):\n\u001B[1;32m   1120\u001B[0m     \u001B[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001B[39;00m\n\u001B[1;32m   1121\u001B[0m     \u001B[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1129\u001B[0m     \u001B[38;5;66;03m# Returns a 2-tuple:\u001B[39;00m\n\u001B[1;32m   1130\u001B[0m     \u001B[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001B[39;00m\n\u001B[1;32m   1131\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1132\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1133\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n\u001B[1;32m   1134\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1135\u001B[0m         \u001B[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001B[39;00m\n\u001B[1;32m   1136\u001B[0m         \u001B[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001B[39;00m\n\u001B[1;32m   1137\u001B[0m         \u001B[38;5;66;03m# worker failures.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/multiprocessing/queues.py:113\u001B[0m, in \u001B[0;36mQueue.get\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[1;32m    112\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m deadline \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[0;32m--> 113\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    114\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll():\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:257\u001B[0m, in \u001B[0;36m_ConnectionBase.poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_closed()\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_readable()\n\u001B[0;32m--> 257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:424\u001B[0m, in \u001B[0;36mConnection._poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_poll\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout):\n\u001B[0;32m--> 424\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    425\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(r)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:931\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    928\u001B[0m     deadline \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic() \u001B[38;5;241m+\u001B[39m timeout\n\u001B[1;32m    930\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 931\u001B[0m     ready \u001B[38;5;241m=\u001B[39m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    932\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ready:\n\u001B[1;32m    933\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [key\u001B[38;5;241m.\u001B[39mfileobj \u001B[38;5;28;01mfor\u001B[39;00m (key, events) \u001B[38;5;129;01min\u001B[39;00m ready]\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/selectors.py:416\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    414\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 416\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[1;32m    418\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Train and evaluate pretrained models\n",
    "pretrained_results_df, pretrained_metrics = train_and_evaluate_models(pretrained_models, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Pretrained</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EfficientNet</td>\n",
       "      <td>True</td>\n",
       "      <td>0.829306</td>\n",
       "      <td>0.827624</td>\n",
       "      <td>0.827476</td>\n",
       "      <td>0.827624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ResNet</td>\n",
       "      <td>True</td>\n",
       "      <td>0.751379</td>\n",
       "      <td>0.748020</td>\n",
       "      <td>0.748540</td>\n",
       "      <td>0.748020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VGG</td>\n",
       "      <td>True</td>\n",
       "      <td>0.317313</td>\n",
       "      <td>0.330099</td>\n",
       "      <td>0.319110</td>\n",
       "      <td>0.330099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MobileNet</td>\n",
       "      <td>True</td>\n",
       "      <td>0.779271</td>\n",
       "      <td>0.777822</td>\n",
       "      <td>0.777975</td>\n",
       "      <td>0.777822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DenseNet</td>\n",
       "      <td>True</td>\n",
       "      <td>0.799960</td>\n",
       "      <td>0.798317</td>\n",
       "      <td>0.798242</td>\n",
       "      <td>0.798317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Pretrained  Precision    Recall  F1 Score  Accuracy\n",
       "0  EfficientNet        True   0.829306  0.827624  0.827476  0.827624\n",
       "1        ResNet        True   0.751379  0.748020  0.748540  0.748020\n",
       "2           VGG        True   0.317313  0.330099  0.319110  0.330099\n",
       "3     MobileNet        True   0.779271  0.777822  0.777975  0.777822\n",
       "4      DenseNet        True   0.799960  0.798317  0.798242  0.798317"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ruqjW20amREK"
   },
   "outputs": [],
   "source": [
    "current_timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "filename = f'results_pretrained_{current_timestamp}.csv'\n",
    "pretrained_results_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lz5qTQqme483",
    "outputId": "ebbe4913-a553-4ae9-89a8-afa7e874965a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validating EfficientNet (Pretrained: False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:18<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 4.375394216943734, Val Loss: 4.228005222127408, Val Accuracy: 0.05638613861386139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:17<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 3.8542740870038523, Val Loss: 3.7903696464586862, Val Accuracy: 0.11861386138613861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:17<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 3.378885016114273, Val Loss: 3.229848986939539, Val Accuracy: 0.22287128712871287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:17<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 2.9009540657704487, Val Loss: 2.7726997363416452, Val Accuracy: 0.31445544554455446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:17<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 2.4853109581806168, Val Loss: 2.573833977119832, Val Accuracy: 0.36178217821782177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:17<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 2.113519678477346, Val Loss: 2.2089012242570707, Val Accuracy: 0.4443069306930693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:17<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 1.8418141792827565, Val Loss: 1.990254767333405, Val Accuracy: 0.4925247524752475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:17<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 1.3377747290401252, Val Loss: 1.7142092087600804, Val Accuracy: 0.5613366336633664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:17<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 1.185565534481503, Val Loss: 1.696402202678632, Val Accuracy: 0.5695049504950495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:17<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 1.0945558421017891, Val Loss: 1.7048886999299255, Val Accuracy: 0.5677722772277227\n",
      "Saved trained model at /Trained_Models/EfficientNet_non_pretrained.pt\n",
      "Evaluating EfficientNet (Pretrained: False)\n",
      "Precision: 0.5748205129472024, Recall: 0.5742574257425742, F1 Score: 0.5716025749300604, Accuracy: 0.5742574257425742\n",
      "Training and validating ResNet (Pretrained: False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 4.253155624823449, Val Loss: 4.122869560990153, Val Accuracy: 0.07811881188118812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 3.6749575052020353, Val Loss: 3.8199616383902635, Val Accuracy: 0.13173267326732674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 3.253664806001023, Val Loss: 3.4093002941035015, Val Accuracy: 0.19806930693069308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 2.843223584688097, Val Loss: 3.0478779877288433, Val Accuracy: 0.26321782178217823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 2.467091228127049, Val Loss: 2.927686593200587, Val Accuracy: 0.2906930693069307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 2.160091203903033, Val Loss: 2.8466111987451965, Val Accuracy: 0.31925742574257426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 1.893175961308531, Val Loss: 2.7008066863953313, Val Accuracy: 0.37143564356435643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 1.3013152196088853, Val Loss: 1.8015197538122345, Val Accuracy: 0.5500495049504951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 1.1220241612906061, Val Loss: 1.793411660043499, Val Accuracy: 0.5543564356435644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:06<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.99982805802934, Val Loss: 1.8884781968744495, Val Accuracy: 0.550940594059406\n",
      "Saved trained model at /Trained_Models/ResNet_non_pretrained.pt\n",
      "Evaluating ResNet (Pretrained: False)\n",
      "Precision: 0.5637328055317504, Recall: 0.5523762376237624, F1 Score: 0.551025507950444, Accuracy: 0.5523762376237624\n",
      "Training and validating VGG (Pretrained: False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:45<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 8.658925445501556, Val Loss: 4.6151470836204815, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:45<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 4.615432458664106, Val Loss: 4.615135663672339, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:45<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 4.615392500743108, Val Loss: 4.6151297665849516, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:45<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 4.615399587885998, Val Loss: 4.615129651902597, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:45<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 4.615371218657235, Val Loss: 4.615130629720567, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:44<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 4.615424505640023, Val Loss: 4.6151293018196204, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:44<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 4.615389737841885, Val Loss: 4.615129325963274, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:44<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 4.615096625868595, Val Loss: 4.615129132814046, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:44<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 4.615106926928358, Val Loss: 4.6151288370542884, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:45<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 4.615122049724152, Val Loss: 4.615127992026413, Val Accuracy: 0.009900990099009901\n",
      "Saved trained model at /Trained_Models/VGG_non_pretrained.pt\n",
      "Evaluating VGG (Pretrained: False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 9.802960494069208e-05, Recall: 0.009900990099009901, F1 Score: 0.00019413706076490002, Accuracy: 0.009900990099009901\n",
      "Training and validating MobileNet (Pretrained: False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:45<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 4.098104840151239, Val Loss: 4.912214083007619, Val Accuracy: 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:45<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 3.4789439332183947, Val Loss: 4.373997048486637, Val Accuracy: 0.06668316831683169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:45<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 3.033961319320899, Val Loss: 3.360474853575984, Val Accuracy: 0.2253960396039604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:45<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 2.6509630783370257, Val Loss: 4.233963552909561, Val Accuracy: 0.174009900990099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:45<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 2.297640343865763, Val Loss: 2.924119659616977, Val Accuracy: 0.3149009900990099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:44<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 2.0091255696671966, Val Loss: 2.699534363384488, Val Accuracy: 0.36044554455445543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:44<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 1.757824422650389, Val Loss: 2.3875065166738967, Val Accuracy: 0.4268316831683168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:45<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 1.2378782283528187, Val Loss: 1.9444368783431718, Val Accuracy: 0.5143069306930693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:45<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 1.0748085142903379, Val Loss: 1.9683504225332527, Val Accuracy: 0.5220792079207921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:44<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.9730644462771364, Val Loss: 2.046131933791728, Val Accuracy: 0.520940594059406\n",
      "Saved trained model at /Trained_Models/MobileNet_non_pretrained.pt\n",
      "Evaluating MobileNet (Pretrained: False)\n",
      "Precision: 0.5214854151710981, Recall: 0.5201980198019802, F1 Score: 0.5171336156977725, Accuracy: 0.5201980198019802\n",
      "Training and validating DenseNet (Pretrained: False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:15<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 3.8438786616824596, Val Loss: 3.7369838605953167, Val Accuracy: 0.1404950495049505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 3.1280533329244125, Val Loss: 3.2476641769650616, Val Accuracy: 0.22777227722772278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 2.598802169737833, Val Loss: 3.1820791914493225, Val Accuracy: 0.26034653465346536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 2.2120876828685994, Val Loss: 2.447665984117532, Val Accuracy: 0.39910891089108913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 1.9077451784257855, Val Loss: 2.4208519383321834, Val Accuracy: 0.41767326732673266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 1.6743637710702117, Val Loss: 2.2103187502185, Val Accuracy: 0.457970297029703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 1.4758727830239582, Val Loss: 2.005479040025156, Val Accuracy: 0.5014356435643564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:14<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 1.0241381676618804, Val Loss: 1.4399222588237328, Val Accuracy: 0.6272772277227723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.8998948043003839, Val Loss: 1.4025480694408659, Val Accuracy: 0.6384653465346535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.8340397582587783, Val Loss: 1.3974817772454853, Val Accuracy: 0.6416831683168317\n",
      "Saved trained model at /Trained_Models/DenseNet_non_pretrained.pt\n",
      "Evaluating DenseNet (Pretrained: False)\n",
      "Precision: 0.6457570051936392, Recall: 0.6420792079207921, F1 Score: 0.6412335839847823, Accuracy: 0.6420792079207921\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate non-pretrained models\n",
    "non_pretrained_results_df, non_pretrained_metrics = train_and_evaluate_models(non_pretrained_models, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Pretrained</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EfficientNet</td>\n",
       "      <td>False</td>\n",
       "      <td>0.574821</td>\n",
       "      <td>0.574257</td>\n",
       "      <td>0.571603</td>\n",
       "      <td>0.574257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ResNet</td>\n",
       "      <td>False</td>\n",
       "      <td>0.563733</td>\n",
       "      <td>0.552376</td>\n",
       "      <td>0.551026</td>\n",
       "      <td>0.552376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VGG</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.009901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MobileNet</td>\n",
       "      <td>False</td>\n",
       "      <td>0.521485</td>\n",
       "      <td>0.520198</td>\n",
       "      <td>0.517134</td>\n",
       "      <td>0.520198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DenseNet</td>\n",
       "      <td>False</td>\n",
       "      <td>0.645757</td>\n",
       "      <td>0.642079</td>\n",
       "      <td>0.641234</td>\n",
       "      <td>0.642079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Pretrained  Precision    Recall  F1 Score  Accuracy\n",
       "0  EfficientNet       False   0.574821  0.574257  0.571603  0.574257\n",
       "1        ResNet       False   0.563733  0.552376  0.551026  0.552376\n",
       "2           VGG       False   0.000098  0.009901  0.000194  0.009901\n",
       "3     MobileNet       False   0.521485  0.520198  0.517134  0.520198\n",
       "4      DenseNet       False   0.645757  0.642079  0.641234  0.642079"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_pretrained_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "filename = f'results_nonpretrained_{current_timestamp}.csv'\n",
    "non_pretrained_results_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'pt_metrics_{current_timestamp}.pickle', 'wb') as handle:\n",
    "    pickle.dump(pretrained_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'npt_metrics_{current_timestamp}.pickle', 'wb') as handle:\n",
    "    pickle.dump(non_pretrained_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting\n",
    "for model_name in pretrained_models.keys():\n",
    "    pt_epochs_range = range(1, 10 + 1)\n",
    "    npt_epochs_range = range(1, 20 + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot for pretrained model\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(pt_epochs_range, pretrained_metrics[model_name][\"train_losses\"], color='blue', label='Training Loss')\n",
    "    plt.plot(pt_epochs_range, pretrained_metrics[model_name][\"val_losses\"], color='red', label='Validation Loss')\n",
    "    plt.plot(pt_epochs_range, pretrained_metrics[model_name][\"train_accuracies\"], color='orange', label='Training Accuracy')\n",
    "    plt.plot(pt_epochs_range, pretrained_metrics[model_name][\"val_accuracies\"], color='green', label='Validation Accuracy')\n",
    "    plt.title(f'{model_name} Pretrained')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Metrics')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot for non-pretrained model\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(npt_epochs_range, non_pretrained_metrics[model_name][\"train_losses\"], color='blue', label='Training Loss')\n",
    "    plt.plot(npt_epochs_range, non_pretrained_metrics[model_name][\"val_losses\"], color='red', label='Validation Loss')\n",
    "    plt.plot(npt_epochs_range, non_pretrained_metrics[model_name][\"train_accuracies\"], color='orange', label='Training Accuracy')\n",
    "    plt.plot(npt_epochs_range, non_pretrained_metrics[model_name][\"val_accuracies\"], color='green', label='Validation Accuracy')\n",
    "    plt.title(f'{model_name} Non-Pretrained')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Metrics')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
